
我们的研究内容是"用于日常交流的视觉语音识别"，主要针对于唇语视觉识别语音，现阶段打算研究的模型是Auto-AVSR(自动标注辅助下的视听语音识别)以下是相关内容，根据这些内容生成我们研究的研究动机。"
1.简介
视觉语音识别 （VSR） 是计算机的一项任务，它仅通过观察说话者的嘴唇运动来推断说话者在视频中所说的内容。由于视觉流不受背景噪声的影响，因此随着噪声水平的增加，VSR 模型可以提高音频识别模型的性能。近年来，VSR因其在嘈杂视频语音识别、残疾人辅助等实际应用中的优势而引起了广泛的研究关注。
1.1
由于两个主要原因，传统的 VSR 模型遇到了精度提高有限的困难：（1） 缺乏大型转录视听数据集导致模型只能识别有限的词汇并且只能在实验室环境中工作;（2） 手工制作的视觉特征中的不准确性标签可能不是 VSR 应用的最佳选择

1.2
深度学习的进步使端到端模型的使用成为可能，该模型学习直接从原始图像中提取与 VSR 相关的特征。这些发展导致了新一代基于深度学习的 VSR 模型，这些模型实现了更高的精度

1.3
以往对VSR模型的研究主要采用新闻广播视频作为数据集，其中说话者发音较好，但这些数据无法满足日常交流文本推理的要求。

1.4
随着VSR模型的日益成熟，我们专注于将其引入日常使用的实际应用中。
鉴于日常交流中具有不同口音和情感表达的演讲，我们的目标是弄清楚当前的 VSR 模型是否运行良好，并努力提高其性能。该研究计划也需要一个新的数据集。我们的基线 VSR 模型是 2023 年 6 月发布的 [2] 中提出的 Auto-AVSR。

1.5
在文章[2]中，马等人提出了一种最先进的端到端VSR模型架构，该架构使用超参数优化，时间掩码和基于辅助任务的方法，该方法将英语，西班牙语和普通话的小规模公开数据集上的单词错误率（WAR）大大降低到30以下。此外，较大的数据集仍然提高了其 VSR 模型的性能。然而，目前仍有一些问题尚未解决，例如，在极端情况下，人脸识别的鲁棒性不足，例如模糊的移动场景。在情感视觉语音识别任务中，面部表情的大幅变化和不稳定的语速也是VSR模型面临的一大挑战。"




大多数工作都旨在改善时态模型或训练策略

#### 研究动机和问题解决方案

动机:
我们的研究致力于"用于日常交流的视觉语音识别"，旨在通过观察说话者的嘴唇运动，实现对说话内容的准确推断。以下是我们研究的动机：
    优势和应用广泛性： 视觉语音识别（VSR）在嘈杂视频语音识别和残疾人辅助等实际应用中表现出很大的优势。由于视觉流不受背景噪声的干扰，VSR 模型可以提高音频识别模型的性能，使其在各种环境下都具备应用潜力。

    传统模型的限制： 传统的VSR模型在提高精度方面遇到了困难，主要因为缺乏大型转录视听数据集以及手工制作的视觉特征中存在不准确的标签。这些问题限制了模型的词汇范围和适用环境，使其仅在受控实验室环境中工作。

    深度学习的推动： 随着深度学习的进步，端到端模型的使用成为可能，允许模型直接从原始图像中提取与VSR相关的特征。这种进步推动了基于深度学习的VSR模型的发展，提高了其准确性。

    实际应用需求： 过去的VSR研究主要集中在新闻广播视频等语音发音较好的数据集上，而我们的目标是将VSR模型引入日常交流的实际应用中。这需要解决日常交流中存在的口音、情感表达等多样性，因此需要更具挑战性的数据集和模型。

    基线模型的选择： 我们选择了Auto-AVSR作为基线VSR模型，该模型是由马等人于2023年6月发布的，并采用了一种先进的端到端VSR模型架构。该架构通过超参数优化、时间掩码和基于辅助任务的方法，成功将单词错误率（WAR）降低到30以下，但在极端情况下仍存在一些问题，如对模糊的移动场景和情感变化的鲁棒性不足。

通过解决以上问题，我们的研究旨在推动VSR技术在日常交流中的应用，并提高其性能以满足各种口音、情感表达等多样性的需求。我们也计划构建一个新的数据集，以更好地反映日常交流的实际场景，为VSR模型的训练和评估提供更具挑战性的数据。




pip config set global.index-url http://mirrors.aliyun.com/pypi/simple


echo ". /home/user/miniconda/etc/profile.d/conda.sh" >> ~/.bashrc